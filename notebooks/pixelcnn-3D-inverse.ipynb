{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "import sys\n",
    "sys.path.append('../code/utils/')\n",
    "sys.path.append('../code')\n",
    "import tools\n",
    "from layers import wide_resnet\n",
    "import datatools as dtools\n",
    "from time import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.slim import add_arg_scope\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_probability\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tensorflow_probability.distributions\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel CNN 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# def get_weights(shape, name, horizontal, mask_mode='noblind', mask=None):\n",
    "#     weights_initializer = tf.contrib.layers.xavier_initializer()\n",
    "# #     weights_initializer = tf.ones_initializer()\n",
    "#     W = tf.get_variable(name, shape, tf.float32, weights_initializer)\n",
    "\n",
    "#     '''\n",
    "#         Use of masking to hide subsequent pixel values \n",
    "#     '''\n",
    "#     if mask:\n",
    "#         filter_mid_y = shape[0]//2\n",
    "#         filter_mid_x = shape[1]//2\n",
    "#         mask_filter = np.ones(shape, dtype=np.float32)\n",
    "#         if mask_mode == 'noblind':\n",
    "#             if horizontal:\n",
    "#                 # All rows after center must be zero\n",
    "#                 mask_filter[filter_mid_y+1:, :, :, :] = 0.0\n",
    "#                 # All columns after center in center row must be zero\n",
    "#                 mask_filter[filter_mid_y, filter_mid_x+1:, :, :] = 0.0\n",
    "#             else:\n",
    "#                 if mask == 'a':\n",
    "#                     # In the first layer, can ONLY access pixels above it\n",
    "#                     mask_filter[filter_mid_y:, :, :, :] = 0.0\n",
    "#                 else:\n",
    "#                     # In the second layer, can access pixels above or even with it.\n",
    "#                     # Reason being that the pixels to the right or left of the current pixel\n",
    "#                     #  only have a receptive field of the layer above the current layer and up.\n",
    "#                     mask_filter[filter_mid_y+1:, :, :, :] = 0.0\n",
    "\n",
    "#             if mask == 'a':\n",
    "#                 # Center must be zero in first layer\n",
    "#                 mask_filter[filter_mid_y, filter_mid_x, :, :] = 0.0\n",
    "#         else:\n",
    "#             mask_filter[filter_mid_y, filter_mid_x+1:, :, :] = 0.\n",
    "#             mask_filter[filter_mid_y+1:, :, :, :] = 0.\n",
    "\n",
    "#             if mask == 'a':\n",
    "#                 mask_filter[filter_mid_y, filter_mid_x, :, :] = 0.\n",
    "                \n",
    "#         W *= mask_filter \n",
    "#     return W\n",
    "\n",
    "\n",
    "def get_weights(shape, name, horizontal, mask_mode='noblind', mask=None):\n",
    "    weights_initializer = tf.contrib.layers.xavier_initializer()\n",
    "#     weights_initializer = tf.ones_initializer()\n",
    "    W = tf.get_variable(name, shape, tf.float32, weights_initializer)\n",
    "    if horizontal: orientation = 1\n",
    "    else: orientation = 0\n",
    "#     print(orientation)\n",
    "    '''\n",
    "        Use of masking to hide subsequent pixel values \n",
    "    '''\n",
    "    if mask:\n",
    "        filter_mid_y = shape[0]//2\n",
    "        filter_mid_x = shape[1]//2\n",
    "        mask_filter = np.ones(shape, dtype=np.float32)\n",
    "        if mask_mode == 'noblind':\n",
    "                \n",
    "            if orientation == 0:\n",
    "                if mask == 'a':\n",
    "                    # In the first layer, can ONLY access pixels above it\n",
    "                    mask_filter[filter_mid_y:, :, :, :] = 0.0\n",
    "                else:\n",
    "                    # In the second layer, can access pixels above or even with it.\n",
    "                    # Reason being that the pixels to the right or left of the current pixel\n",
    "                    #  only have a receptive field of the layer above the current layer and up.\n",
    "                    mask_filter[filter_mid_y+1:, :, :, :] = 0.0\n",
    "\n",
    "            elif orientation == 1:\n",
    "                # All rows after center must be zero\n",
    "                mask_filter[filter_mid_y+1:, :, :, :] = 0.0\n",
    "                # All columns after center in center row must be zero\n",
    "                mask_filter[filter_mid_y, filter_mid_x+1:, :, :] = 0.0\n",
    "                \n",
    "            if mask == 'a':\n",
    "                # Center must be zero in first layer\n",
    "                mask_filter[filter_mid_y, filter_mid_x, :, :] = 0.0\n",
    "        else:\n",
    "            mask_filter[filter_mid_y, filter_mid_x+1:, :, :] = 0.\n",
    "            mask_filter[filter_mid_y+1:, :, :, :] = 0.\n",
    "\n",
    "            if mask == 'a':\n",
    "                mask_filter[filter_mid_y, filter_mid_x, :, :] = 0.\n",
    "                \n",
    "        W = W*mask_filter \n",
    "#         W2 = W*mask_filter \n",
    "#         tf.assign(W, W*mask_filter )\n",
    "    \n",
    "    return W\n",
    "\n",
    "\n",
    "def get_bias(shape, name):\n",
    "    return tf.get_variable(name, shape, tf.float32, tf.zeros_initializer)\n",
    "\n",
    "def conv_op(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "class GatedCNN():\n",
    "    def __init__(self, W_shape, fan_in, horizontal, gated=True, payload=None, mask=None, activation=True, conditional=None, conditional_image=None):\n",
    "        self.fan_in = fan_in\n",
    "        in_dim = self.fan_in.get_shape()[-1]\n",
    "        self.W_shape = [W_shape[0], W_shape[1], in_dim, W_shape[2]]  \n",
    "        self.b_shape = W_shape[2]\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.payload = payload\n",
    "        self.mask = mask\n",
    "        self.activation = activation\n",
    "        self.conditional = conditional\n",
    "        self.conditional_image = conditional_image\n",
    "        self.horizontal = horizontal\n",
    "        \n",
    "        if gated:\n",
    "            self.gated_conv()\n",
    "        else:\n",
    "            self.simple_conv()\n",
    "\n",
    "\n",
    "    def gated_conv(self):\n",
    "        W_f = get_weights(self.W_shape, \"v_W\", self.horizontal, mask=self.mask)\n",
    "        W_g = get_weights(self.W_shape, \"h_W\", self.horizontal, mask=self.mask)\n",
    "\n",
    "        b_f_total = get_bias(self.b_shape, \"v_b\")\n",
    "        b_g_total = get_bias(self.b_shape, \"h_b\")\n",
    "#         if self.conditional is not None:\n",
    "#             h_shape = int(self.conditional.get_shape()[1])\n",
    "#             V_f = get_weights([h_shape, self.W_shape[3]], \"v_V\", self.horizontal)\n",
    "#             b_f = tf.matmul(self.conditional, V_f)\n",
    "#             V_g = get_weights([h_shape, self.W_shape[3]], \"h_V\", self.horizontal)\n",
    "#             b_g = tf.matmul(self.conditional, V_g)\n",
    "\n",
    "#             b_f_shape = tf.shape(b_f)\n",
    "#             b_f = tf.reshape(b_f, (b_f_shape[0], 1, 1, b_f_shape[1]))\n",
    "#             b_g_shape = tf.shape(b_g)\n",
    "#             b_g = tf.reshape(b_g, (b_g_shape[0], 1, 1, b_g_shape[1]))\n",
    "\n",
    "#             b_f_total = b_f_total + b_f\n",
    "#             b_g_total = b_g_total + b_g\n",
    "        if self.conditional_image is not None:\n",
    "\n",
    "            b_f_total = b_f_total + tf.layers.conv3d(self.conditional_image, self.in_dim, 1, use_bias=False, name=\"ci_f\")\n",
    "            b_g_total = b_g_total + tf.layers.conv3d(self.conditional_image, self.in_dim, 1, use_bias=False, name=\"ci_g\")\n",
    "\n",
    "        conv_f = conv_op(self.fan_in, W_f)\n",
    "        conv_g = conv_op(self.fan_in, W_g)\n",
    "       \n",
    "        if self.payload is not None:\n",
    "            conv_f += self.payload\n",
    "            conv_g += self.payload\n",
    "\n",
    "#         self.fan_out = tf.multiply(tf.tanh(conv_f + b_f_total), tf.sigmoid(conv_g + b_g_total))\n",
    "        self.fan_out = tf.multiply(1., conv_f + b_f_total)\n",
    "        \n",
    "        \n",
    "\n",
    "    def simple_conv(self):\n",
    "        W = get_weights(self.W_shape, \"W\", self.horizontal, mask_mode=\"standard\", mask=self.mask)\n",
    "        b = get_bias(self.b_shape, \"b\")\n",
    "        conv = conv_op(self.fan_in, W)\n",
    "        if self.activation: \n",
    "#             self.fan_out = tf.nn.relu(tf.add(conv, b))\n",
    "            self.fan_out = tf.identity(tf.add(conv, b))\n",
    "        else:\n",
    "            self.fan_out = tf.add(conv, b)\n",
    "\n",
    "    def output(self):\n",
    "        return self.fan_out \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.layers.conv2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelCNN(object):\n",
    "    def __init__(self, X, full_horizontal=True, h=None):\n",
    "        self.X = X\n",
    "        self.X_norm = X\n",
    "        v_stack_in, h_stack_in = self.X_norm, self.X_norm\n",
    "        self.h = None\n",
    "        nlayers = 5\n",
    "        f_map = 16\n",
    "        \n",
    "        for i in range(nlayers):\n",
    "            filter_size = 3 if i > 0 else 3\n",
    "            mask = 'b' if i > 0 else 'a'\n",
    "            residual = True if i > 0 else False\n",
    "            i = str(i)\n",
    "            \n",
    "            with tf.variable_scope(\"v_stack\"+i):\n",
    "                v_stack = GatedCNN([filter_size, filter_size, f_map], v_stack_in, False, mask=mask, conditional=self.h).output()\n",
    "                v_stack_in = v_stack\n",
    "\n",
    "            with tf.variable_scope(\"v_stack_1\"+i):\n",
    "                v_stack_1 = GatedCNN([1, 1, f_map], v_stack_in, False, gated=False, mask=None).output()\n",
    "\n",
    "            with tf.variable_scope(\"h_stack\"+i):\n",
    "                h_stack = GatedCNN([filter_size if full_horizontal else 1, filter_size, f_map], h_stack_in, True, payload=v_stack_1, mask=mask, conditional=self.h).output()\n",
    "\n",
    "            with tf.variable_scope(\"h_stack_1\"+i):\n",
    "                h_stack_1 = GatedCNN([1, 1, f_map], h_stack, True, gated=False, mask=None).output()\n",
    "                if residual:\n",
    "                    h_stack_1 += h_stack_in # Residual connection\n",
    "                h_stack_in = h_stack_1\n",
    "\n",
    "        with tf.variable_scope(\"fc_1\"):\n",
    "            fc1 = GatedCNN([1, 1, f_map], h_stack_in, True, gated=False, mask='b').output()\n",
    "\n",
    "        with tf.variable_scope(\"fc_2\"):\n",
    "            self.fc2 = GatedCNN([1, 1, 1], fc1, True, gated=False, mask='b', activation=False).output()\n",
    "        self.loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.fc2, labels=self.X))\n",
    "        self.pred = tf.nn.sigmoid(self.fc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "# hsize, wsize = 9, 9 \n",
    "# xx = np.arange(hsize*wsize).reshape(hsize, wsize)\n",
    "# # xx = np.ones((5, 5))\n",
    "# xx4 = xx.reshape(1, hsize, wsize, 1)\n",
    "\n",
    "# X = tf.placeholder(tf.float32, shape=[None, hsize, wsize, 1])\n",
    "# pix = PixelCNN(X)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.initializers.global_variables())\n",
    "#     pred = sess.run(tf.squeeze(pix.fc2), {X:xx4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.02949868  0.02388657  0.02699176  0.0267434 ]\n",
      " [ 0.01159488  0.02023843  0.01792445  0.0334581   0.03604671]\n",
      " [ 0.02068383 -0.00580058 -0.0206751   0.0140147   0.03067714]\n",
      " [ 0.03015262  0.02153223  0.01293455  0.05855225  0.0725489 ]\n",
      " [ 0.03462861  0.04502065  0.03099092  0.07879493  0.07767848]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "hsize, wsize = 5, 5\n",
    "X = tf.placeholder(tf.float32, shape=[None, hsize, wsize, 1])\n",
    "pix = PixelCNN(X)\n",
    "\n",
    "\n",
    "preds = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initializers.global_variables())\n",
    "    \n",
    "    index = np.arange(hsize*wsize).reshape(hsize, wsize)\n",
    "    xx = np.ones_like(index)*0.1\n",
    "#     xx = index.copy()\n",
    "\n",
    "    xx4 = xx.reshape(1, hsize, wsize, 1)\n",
    "    pred0 = sess.run(tf.squeeze(pix.fc2), {X:xx4})\n",
    "\n",
    "    print(pred0)\n",
    "    for i in range(hsize):\n",
    "        tmp = []\n",
    "        for j in range(wsize):\n",
    "            xxn = xx4.copy()\n",
    "            xxn[0, i, j, 0] = -np.pi*np.e \n",
    "            tmp.append(sess.run(tf.squeeze(pix.fc2), {X:xxn}))\n",
    "        preds.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ii in range(hsize):\n",
    "    for jj in range(wsize):\n",
    "\n",
    "        miss = set(np.arange(index[ii, jj]+1, hsize*wsize, 1)) - \\\n",
    "                        set(index[(pred0 - preds[ii][jj]).astype('bool')])\n",
    "        if len(miss) >0: \n",
    "            print('less', ii, jj, index[ii, jj], miss)\n",
    "            plt.imshow((pred0 - preds[ii][jj]).astype('bool'))\n",
    "            plt.axhline(ii)\n",
    "            plt.axvline(jj)\n",
    "            for ax in plt.gcf().axes: ax.set_xticks(np.arange(hsize))\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "        miss2 =  set(index[(pred0 - preds[ii][jj]).astype('bool')]) - \\\n",
    "                        set(np.arange(xx[ii, jj]+1, hsize*wsize, 1))\n",
    "#         if len(miss2) >0: print('more', ii, jj, xx[ii, jj], miss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ii, jj = 2, 3\n",
    "ii, jj = np.random.randint(0, hsize, 2)\n",
    "print(ii, jj)\n",
    "plt.imshow((pred0 - preds[ii][jj]).astype('bool'))\n",
    "plt.axhline(ii)\n",
    "plt.axvline(jj)\n",
    "for ax in plt.gcf().axes: ax.set_xticks(np.arange(hsize))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  2.5486066 , -0.48487067,  0.2682801 , -0.02145687],\n",
       "       [ 1.2749101 , -2.7407868 , -0.21258064,  0.3476851 , -0.10706534],\n",
       "       [ 0.9055164 , -4.048314  , -0.23004179,  1.108602  , -0.16162294],\n",
       "       [ 1.8019446 ,  0.6245255 ,  0.25824994,  0.33241373, -0.30502596],\n",
       "       [ 1.3885789 ,  1.9354916 , -0.29802603,  0.33593646, -0.15283936]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred0 - preds[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel CNN 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def get_weights3d(shape, name, orientation, mask_mode='noblind', mask=None):\n",
    "    weights_initializer = tf.contrib.layers.xavier_initializer()\n",
    "#     weights_initializer = tf.ones_initializer()\n",
    "    W = tf.get_variable(name, shape, tf.float32, weights_initializer)\n",
    "\n",
    "    '''\n",
    "        Use of masking to hide subsequent pixel values \n",
    "    '''\n",
    "    if mask:\n",
    "        filter_mid_x = shape[0]//2\n",
    "        filter_mid_y = shape[1]//2\n",
    "        filter_mid_z = shape[2]//2\n",
    "        \n",
    "        mask_filter = np.ones(shape, dtype=np.float32)\n",
    "        if mask_mode == 'noblind':\n",
    "                \n",
    "            if orientation == 0:\n",
    "                if mask == 'a':\n",
    "                    mask_filter[filter_mid_x:, :, :, :, :] = 0.0\n",
    "                else:\n",
    "                    mask_filter[filter_mid_x+1:, :, :, :, :] = 0.0\n",
    "\n",
    "            elif orientation == 1 :\n",
    "                mask_filter[filter_mid_x+1:, :, :, :, :] = 0.0\n",
    "                if mask == 'a':\n",
    "                    mask_filter[filter_mid_x:, filter_mid_y:, :, :, :] = 0.0\n",
    "                else:\n",
    "                    mask_filter[filter_mid_x:, filter_mid_y+1:, :, :, :] = 0.0\n",
    "\n",
    "            elif orientation == 2:\n",
    "                mask_filter[filter_mid_x+1:, :, :, :, :] = 0.0\n",
    "                mask_filter[filter_mid_x:, filter_mid_y+1:, :, :, :] = 0.0\n",
    "                mask_filter[filter_mid_x:, filter_mid_y:, filter_mid_z+1:, :, :] = 0.0\n",
    "\n",
    "            if mask == 'a':\n",
    "                # Center must be zero in first layer\n",
    "                mask_filter[filter_mid_x, filter_mid_y, filter_mid_z, :, :] = 0.0\n",
    "\n",
    "        else:\n",
    "            mask_filter[filter_mid_x, filter_mid_y:, filter_mid_z+1:, :, :] = 0.\n",
    "            mask_filter[filter_mid_x, filter_mid_y+1:, :, :, :] = 0.\n",
    "            mask_filter[filter_mid_x+1:, :, :, :, :] = 0.\n",
    "\n",
    "            if mask == 'a':\n",
    "                mask_filter[filter_mid_x, filter_mid_y, filter_mid_z, :, :] = 0.\n",
    "                \n",
    "        W = W*mask_filter \n",
    "#         W *= mask_filter\n",
    "#         W.assign(W * mask_filter)\n",
    "    return W\n",
    "\n",
    "def get_bias(shape, name):\n",
    "    return tf.get_variable(name, shape, tf.float32, tf.zeros_initializer)\n",
    "\n",
    "def conv_op3d(x, W):\n",
    "    return tf.nn.conv3d(x, W, strides=[1,1,1,1,1], padding='SAME')\n",
    "\n",
    "\n",
    "\n",
    "class GatedCNN():\n",
    "    def __init__(self, W_shape, fan_in, orientation, gated=True, payload=None, mask=None, \n",
    "                 activation=True, conditional=None, conditional_image=None, cfilter_size=1):\n",
    "        self.fan_in = fan_in\n",
    "        in_dim = self.fan_in.get_shape()[-1]\n",
    "        self.W_shape = [W_shape[0], W_shape[1], W_shape[2], in_dim, W_shape[3]]  \n",
    "        self.b_shape = W_shape[3]\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.payload = payload\n",
    "        self.mask = mask\n",
    "        self.activation = activation\n",
    "        self.conditional = conditional\n",
    "        self.conditional_image = conditional_image\n",
    "        self.orientation = orientation\n",
    "        self.cfilter_size = cfilter_size\n",
    "        \n",
    "        if gated:\n",
    "            self.gated_conv()\n",
    "        else:\n",
    "            self.simple_conv()\n",
    "\n",
    "\n",
    "    def gated_conv(self):\n",
    "        W_f = get_weights3d(self.W_shape, \"v_W\", self.orientation, mask=self.mask)\n",
    "        W_g = get_weights3d(self.W_shape, \"h_W\", self.orientation, mask=self.mask)\n",
    "\n",
    "        b_f_total = get_bias(self.b_shape, \"v_b\")\n",
    "        b_g_total = get_bias(self.b_shape, \"h_b\")\n",
    "\n",
    "        if self.conditional_image is not None:\n",
    "            V_f = tf.layers.conv3d(self.conditional_image, self.in_dim, self.cfilter_size, \n",
    "                                   padding='same', use_bias=False, name=\"ci_f\")\n",
    "            V_g = tf.layers.conv3d(self.conditional_image, self.in_dim, self.cfilter_size, \n",
    "                                   padding='same', use_bias=False, name=\"ci_g\")\n",
    "            b_f_total = b_f_total + V_f\n",
    "            b_g_total = b_g_total + V_g\n",
    "            \n",
    "        conv_f = conv_op3d(self.fan_in, W_f)\n",
    "        conv_g = conv_op3d(self.fan_in, W_g)\n",
    "       \n",
    "        if self.payload is not None:\n",
    "            conv_f += self.payload\n",
    "            conv_g += self.payload\n",
    "\n",
    "        self.fan_out = tf.multiply(tf.tanh(conv_f + b_f_total), tf.sigmoid(conv_g + b_g_total))\n",
    "#         self.fan_out = conv_f + b_f_total\n",
    "        \n",
    "        \n",
    "\n",
    "    def simple_conv(self):\n",
    "        W = get_weights3d(self.W_shape, \"W\", self.orientation, mask_mode=\"standard\", mask=self.mask)\n",
    "        b = get_bias(self.b_shape, \"b\")\n",
    "        conv = conv_op3d(self.fan_in, W)\n",
    "        if self.activation: \n",
    "            self.fan_out = tf.nn.leaky_relu(tf.add(conv, b))\n",
    "        else:\n",
    "            self.fan_out = tf.add(conv, b)\n",
    "\n",
    "    def output(self):\n",
    "        return self.fan_out \n",
    "\n",
    "\n",
    "class PixelCNN3D(object):\n",
    "    def __init__(self, X, full_horizontal=True, h=None):\n",
    "        self.X = X\n",
    "        self.X_norm = X\n",
    "        v_stack_in, h_stack_in, d_stack_in = self.X_norm, self.X_norm, self.X_norm\n",
    "        self.h = None\n",
    "        self.im = None #X*0 + 1e-1*np.e\n",
    "        nlayers = 5\n",
    "        f_map = 4\n",
    "        \n",
    "        for i in range(nlayers):\n",
    "            filter_size = 3 if i > 0 else 3\n",
    "            mask = 'b' if i > 0 else 'a'\n",
    "            residual = True if i > 0 else False\n",
    "            i = str(i)\n",
    "            with tf.variable_scope(\"d_stack\"+i):\n",
    "                d_stack = GatedCNN([filter_size, filter_size, filter_size, f_map], \n",
    "                                   d_stack_in, 0, mask=mask, \n",
    "                                   conditional=self.h, conditional_image=self.im).output()\n",
    "                d_stack_in = d_stack\n",
    "\n",
    "            with tf.variable_scope(\"d_stack_1\"+i):\n",
    "                d_stack_1 = GatedCNN([1, 1, 1, f_map], \n",
    "                                     d_stack_in, 0, gated=False, mask=None).output()\n",
    "\n",
    "            with tf.variable_scope(\"v_stack\"+i):\n",
    "                v_stack = GatedCNN([filter_size, filter_size, filter_size, f_map], \n",
    "                                   v_stack_in, 1, payload = d_stack_1, mask=mask, \n",
    "                                   conditional=self.h, conditional_image=self.im).output()\n",
    "                v_stack_in = v_stack\n",
    "\n",
    "            with tf.variable_scope(\"v_stack_1\"+i):\n",
    "                v_stack_1 = GatedCNN([1, 1, 1, f_map], \n",
    "                                     v_stack_in, 1, gated=False, mask=None).output()\n",
    "                \n",
    "            with tf.variable_scope(\"h_stack\"+i):\n",
    "                f0size = filter_size if full_horizontal else 1\n",
    "                h_stack = GatedCNN([f0size, filter_size, filter_size, f_map], \n",
    "                                   h_stack_in, 2, payload=v_stack_1, mask=mask, \n",
    "                                   conditional=self.h, conditional_image=self.im).output()\n",
    "\n",
    "            with tf.variable_scope(\"h_stack_1\"+i):\n",
    "                h_stack_1 = GatedCNN([1, 1, 1, f_map],\n",
    "                                     h_stack, 2, gated=False, mask=None).output()\n",
    "                if residual:\n",
    "                    h_stack_1 += h_stack_in # Residual connection\n",
    "                h_stack_in = h_stack_1\n",
    "\n",
    "        \n",
    "        with tf.variable_scope(\"fc_1\"):\n",
    "            fc1 = GatedCNN([1, 1, 1, f_map], h_stack_in, orientation=None, gated=False, mask='b').output()\n",
    "\n",
    "        with tf.variable_scope(\"fc_2\"):\n",
    "            self.fc2 = GatedCNN([1, 1, 1, 1], fc1, orientation=None, gated=False, mask='b', activation=False).output()\n",
    "        self.loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.fc2, labels=self.X))\n",
    "        self.pred = tf.nn.sigmoid(self.fc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a36f3d4852ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m     \"\"\"\n\u001b[0;32m-> 1511\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSessionRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "hsize, wsize, dsize = 5, 5, 5\n",
    "X = tf.placeholder(tf.float32, shape=[None, hsize, wsize, dsize, 1])\n",
    "pix3d = PixelCNN3D(X)\n",
    "\n",
    "\n",
    "preds = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initializers.global_variables())\n",
    "    \n",
    "    index = np.arange(hsize*wsize*dsize).reshape(hsize, wsize, dsize)\n",
    "    xx = np.ones_like(index)*0.1\n",
    "#     xx = index.copy()\n",
    "\n",
    "    xx5 = xx.reshape(1, hsize, wsize, dsize, 1)\n",
    "    pred0 = sess.run(tf.squeeze(pix3d.fc2), {X:xx5})\n",
    "\n",
    "    print(pred0)\n",
    "    for i in range(hsize):\n",
    "        tmp = []\n",
    "        for j in range(wsize):\n",
    "            tmp2 = []\n",
    "            for k in range(dsize):\n",
    "                xxn = xx5.copy()\n",
    "                xxn[0, i, j, k, 0] = -np.pi*np.e \n",
    "                tmp2.append(sess.run(tf.squeeze(pix3d.fc2), {X:xxn}))\n",
    "            tmp.append(tmp2)\n",
    "        preds.append(tmp)\n",
    "        \n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 1 46\n",
      "78 78\n",
      "47 47\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2QAAACzCAYAAADmO9/CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAEcNJREFUeJzt3W+o5fV9J/D3J9fRsZk4zphhVjJDraUUsgabzjApBGyTVIw1tLAPJIWWPBAGFiqzdK5L+8CFEsqSjJT1wfpAtsEFtxXZbUORig1p3KHQ1Wqq6RjbxW3SdZoQ15hEJ9XYpN99MLcwDSb3/Pud7/md83rBhXtnfr/z/vzOeTNzP3PuOVOttQAAALB8b+s9AAAAwKaykAEAAHRiIQMAAOjEQgYAANCJhQwAAKATCxkAAEAnFjIAAIBOLGQAAACdWMgAAAA6uWyIG728rmh78/apz7v62nfkm199bYCJZC47c568N/LtvNm+Uwse6YcaS2eP5rVsXb6VL7/5I0vLTDajs/Nk9ujsOw9uteuO7pn6vAtvvDP79r48wEQyx5T55Rf/MS+/8r1RdDZZ/n07psdyUzJ1dvUyN+Ea5818+gvfebm1dmi34wZZyPbm7XlffWjq824/fWsevuvRASaSuezMefKeaJ9d8DS7G0tn72mP59CRa/KxL71naZnJZnR2nswenb3u6J48+djRqc87e+5Ubrrh3gEmkjmmzBO3vDjAND/crJ1Nln/fjumx3JRMnV29zE24xnkzt6594e8mOc6PLAIAAHRiIQMAAOjEQgYAANCJhQwAAKATCxkAAEAnFjIAAIBOLGQAAACdWMgAAAA6sZABAAB0MtFCVlUfrqq/qaoXquo3hh4K5qWzjI3OMjY6yxjpLato14WsqraS/OcktyZ5d5Jfrqp3Dz0YzEpnGRudZWx0ljHSW1bVJM+QnUjyQmvtb1trbyZ5KMkvDTsWzEVnGRudZWx0ljHSW1bSJAvZu5K8eMnX53d+DVaVzjI2OsvY6CxjpLespMsWdUNVdTLJySQ5sP9gbr/71qlv48CR/bn9zPTnzUPm6uU9sf3ZBU/z1sbY2UP3/VX2XLG19v0ZW2aPzh4+fHXOnjs19W1ceP3wTOfNQ+YqZm4vfJa3sojOJsu/b8f1WG5Kps6uWuYmXOP8mXdOdNQkC9nfJzl6yddHdn7tX2it3Z/k/iS5qg62h+96dKIBLnX7mVszy3nzkLkeed9nbTt7on09h66/Zu37s0mZO6bu7PEb97abbrh36qCz505llvPmIXO9MncsrbPJ8q9zUx7LTcm8xK69HWtne2RuwjUuK3OSH1n8iyQ/UVU/VlWXJ/lokj8adCqYj84yNjrL2OgsY6S3rKRdnyFrrX23qn4tyWNJtpJ8qrX23OCTwYx0lrHRWcZGZxkjvWVVTfQastbaHyf544FngYXRWcZGZxkbnWWM9JZVNNF/DA0AAMDiWcgAAAA6sZABAAB0YiEDAADoxEIGAADQiYUMAACgEwsZAABAJxYyAACATixkAAAAnVjIAAAAOrGQAQAAdGIhAwAA6MRCBgAA0ImFDAAAoBMLGQAAQCcWMgAAgE4sZAAAAJ1YyAAAADqxkAEAAHRiIQMAAOhk14Wsqj5VVS9V1bllDATz0lnGSG8ZG51lbHSWVTXJM2QPJPnwwHPAIj0QnWV8HojeMi4PRGcZlweis6ygXRey1trZJK8sYRZYCJ1ljPSWsdFZxkZnWVVeQwYAANBJtdZ2P6jquiSPtNZu+CHHnExyMkkO7D947BN3n5l6mANH9ucb57819XnzkLl6eae3t/Nqe6XmyV/Xzt523yez54qtfPqO00vLTDajs/NkLqKzye69vbSzhw9ffeyhBz8+dcaF1w9n35Vfm2PK6clcvczt09t56tk3RtHZZPn37Zgey03J1NnVy9yEa5w38wM33/l0a+34bsddNtOtv4XW2v1J7k+Sq+pge/iuR6e+jdvP3JpZzpuHzPXIm8UYO3uifT2Hrr9m7fuzSZnTuLSzx2/c22664d6pb+PsuVOZ5bx5yFyvzGksorPJ8q9zUx7LTcmcxlg72yNzE65xWZl+ZBEAAKCTSd72/veT/HmSn6yq81V1x/Bjwex0ljHSW8ZGZxkbnWVV7foji621X17GILAoOssY6S1jo7OMjc6yqvzIIgAAQCcWMgAAgE4sZAAAAJ1YyAAAADqxkAEAAHRiIQMAAOjEQgYAANCJhQwAAKATCxkAAEAnFjIAAIBOLGQAAACdWMgAAAA6sZABAAB0YiEDAADoxEIGAADQiYUMAACgEwsZAABAJxYyAACATixkAAAAnVjIAAAAOtl1Iauqo1X1uar6YlU9V1WnljEYzEpnGRudZWx0ljHSW1bVZRMc890kp1trn6+qdyR5uqo+01r74sCzwax0lrHRWcZGZxkjvWUl7foMWWvtq621z+98/lqS55O8a+jBYFY6y9joLGOjs4yR3rKqpnoNWVVdl+S9SZ4YYhhYNJ1lbHSWsdFZxkhvWSXVWpvswKp9Sf5nkt9urf3BW/z+ySQnk+TA/oPHPnH3mamHOXBkf75x/ltTnzcPmauXd3p7O6+2V2reGdaxs7fd98nsuWIrn77j9NIyk83o7DyZPTp7+PDVxx568ONTZ1x4/XD2Xfm1eUeVOfLM7dPbeerZN0bR2WT59+2YHstNyVxUZ5Mf3tuxdrZH5iZc47yZH7j5zqdba8d3O26ihayq9iR5JMljrbXf2e34q+pge199aKJBL3X7mVvz8F2PTn3ePGSuXt4T7bNzf3O7rp29pz2eQ9dfk4996T1Ly0w2o7PzZPbo7PEb97YnHzs6dc7Zc6dy0w33zjDh7GSuXuaJW16c+5vbZXU2Wf59O6bHclMyF9HZZLrejqmzPTI34Rrnzdy69oWJFrJJ3mWxkvxukucn+QMXetNZxkZnGRudZYz0llU1yWvI3p/kV5N8sKqe2fn4hYHngnnoLGOjs4yNzjJGestK2vVt71trf5ZkIT+zC8ugs4yNzjI2OssY6S2raqp3WQQAAGBxLGQAAACdWMgAAAA6sZABAAB0YiEDAADoxEIGAADQiYUMAACgEwsZAABAJxYyAACATixkAAAAnVjIAAAAOrGQAQAAdGIhAwAA6MRCBgAA0ImFDAAAoBMLGQAAQCcWMgAAgE4sZAAAAJ1YyAAAADqxkAEAAHSy60JWVXur6smqeraqnquq31rGYDArnWVsdJYx0lvGRmdZVZdNcMx3knywtXahqvYk+bOqerS19r8Gng1mpbOMjc4yRnrL2OgsK2nXhay11pJc2Plyz85HG3IomIfOMjY6yxjpLWOjs6yqiV5DVlVbVfVMkpeSfKa19sSwY8F8dJax0VnGSG8ZG51lFdXFfyyY8OCqq5P8YZI7W2vnvu/3TiY5mSQH9h889om7z0w9zIEj+/ON89+a+rx5yFy9vNPb23m1vVKLmGPdOnvbfZ/Mniu28uk7Ti8tM9mMzs6T2aOzhw9ffeyhBz8+9e1feP1w9l35tUWMKnPEmdunt/PUs28spLPJD+7tIjqbLP++HdNjuSmZOrt6mZtwjfNmfuDmO59urR3f7bipFrIkqar/kOQfWmv3/KBjrqqD7X31oaluN0luP3NrHr7r0anPm4fM1ct7on12Yd/cJuvV2Xva4zl0/TX52Jfes7TMZDM6O09mj84ev3Fve/Kxo1Pf9tlzp3LTDffOM57MNcg8ccuLC/3mNtm9t7N2Nln+fTumx3JTMnV29TI34Rrnzdy69oWJFrJJ3mXx0M6/IqSqrkxyc5K/nmkqWAKdZWx0ljHSW8ZGZ1lVk7zL4rVJ/mtVbeXiAvdwa+2RYceCuegsY6OzjJHeMjY6y0qa5F0Wv5DkvUuYBRZCZxkbnWWM9Jax0VlW1UTvsggAAMDiWcgAAAA6sZABAAB0YiEDAADoxEIGAADQiYUMAACgEwsZAABAJxYyAACATixkAAAAnVzWewBgeR77yjMznXf23M/OfO6sxpR54pZ/GGAaAGATeIYMAACgEwsZAABAJxYyAACATixkAAAAnVjIAAAAOrGQAQAAdGIhAwAA6MRCBgAA0ImFDAAAoBMLGQAAQCcTL2RVtVVVf1lVjww5ECyKzjI2OsvY6Cxjo7OsommeITuV5PmhBoEB6Cxjo7OMjc4yNjrLyrlskoOq6kiS25L8dpJfH3QiWIBpO3s0r+We9vjUOYfu+6ucaF+f+rxZ/Xi+mT1f+XbumTGz/s2Fmc77qW/fm3r7+ZnOndWmZP4zf84yNjrL2Ogsq6paa7sfVPXfk/zHJO9Ist1a+8hbHHMyyckkObD/4LFP3H1m6mEOHNmfb5z/1tTnzUPm6uWd3t7Oq+2Vmid/2s7+663Ljv3Jj/741Dl7rtjKP37ne/OMOpVrvvJ/U2+rvPyvjs50/o/sm23W7/3T5dl625sznTurMWX+fF7MU8++sdTOHj589bGHHvz41DkXXj+cfVd+bZ5RZa5B5vbp7dF0Nln+fTumx3JTMnV29TI34RrnzfzAzXc+3Vo7vttxuz5DVlUfSfJSa+3pqvq5H3Rca+3+JPcnyVV1sD1816NTjHvR7WduzSznzUPmeuRdatbOfuxL75k6a9nXeU/7eg5df01mmTVJHvvKMzOdd/bcv81NN9w707mzGlXmLfPlztLZ4zfubbPMevbcqQ73q8x1ykyW29lk+de5KY/lpmQm69/ZHpmbcI3LypzkNWTvT/KLVfXlJA8l+WBVPTjoVDAfnWVsdJax0VnGRmdZWbsuZK2132ytHWmtXZfko0n+tLX2K4NPBjPSWcZGZxkbnWVsdJZV5v8hAwAA6GSid1n8Z621x5M8PsgkMACdZWx0lrHRWcZGZ1k1niEDAADoxEIGAADQiYUMAACgEwsZAABAJxYyAACATixkAAAAnVjIAAAAOrGQAQAAdGIhAwAA6KRaa4u/0ar/l+TvZjj1nUleXvA4MvtkzpP3o621Q4scZjc6K3POTJ2VObbMMXU2GdffYTKHydTZ1cvchGucN3Oi3g6ykM2qqp5qrR2XOf7MHtfYwyY8ljLXy6bcrzLXyyb8HSZzvWzCfbsJ17isTD+yCAAA0ImFDAAAoJNVW8jul7k2mT2usYdNeCxlrpdNuV9lrpdN+DtM5nrZhPt2E65xKZkr9RoyAACATbJqz5ABAABsjJVZyKrqw1X1N1X1QlX9xhLyPlVVL1XVuaGzdvKOVtXnquqLVfVcVZ1aQubeqnqyqp7dyfytoTMvyd6qqr+sqkeWlblsOjtIps4OaN07u5O5Mb3V2UHydHbYXJ1dfJ7ODpu7nM621rp/JNlK8n+SXJ/k8iTPJnn3wJk3JfnpJOeWdI3XJvnpnc/fkeR/L+EaK8m+nc/3JHkiyc8s6Xp/PcnvJXmkV68Gvj6dHSZTZ4e7vrXv7E7mxvRWZwfJ1Nlhc3V28Zk6O2zuUjq7Ks+QnUjyQmvtb1trbyZ5KMkvDRnYWjub5JUhM74v76uttc/vfP5akueTvGvgzNZau7Dz5Z6dj8FfNFhVR5LcluS/DJ3Vkc4Ok6mzw1n7zu5kbkRvdXYYOjscnR2Gzg5nmZ1dlYXsXUlevOTr8xn4ge2pqq5L8t5c3O6HztqqqmeSvJTkM621wTOT/Kck/z7JPy0hqxedHS5LZ4exUZ1N1r63OruGdHb0dHbYrLXt7KosZBujqvYl+R9J/l1r7dWh81pr32ut/VSSI0lOVNUNQ+ZV1UeSvNRae3rIHJZHZxmjde6tzq4nnWVsdHZxVmUh+/skRy/5+sjOr62VqtqTi8X9b621P1hmdmvtm0k+l+TDA0e9P8kvVtWXc/Gp+g9W1YMDZ/agswPT2YXbiM4mG9FbnV0zOrs2dHYJ1rGzq7KQ/UWSn6iqH6uqy5N8NMkfdZ5poaqqkvxukudba7+zpMxDVXX1zudXJrk5yV8Pmdla+83W2pHW2nW5+Dj+aWvtV4bM7ERnh8nU2eGsfWeTzeitzq4XnV0rOjtc5lp3diUWstbad5P8WpLHcvGFgQ+31p4bMrOqfj/Jnyf5yao6X1V3DJmXi5v2r+bihv3MzscvDJx5bZLPVdUXcvEPic+01tb2rWaXSWcHo7MD2ZDOJnq7NnR2UDo7AJ0d1Fp3tlob/A3MAAAAeAsr8QwZAADAJrKQAQAAdGIhAwAA6MRCBgAA0ImFDAAAoBMLGQAAQCcWMgAAgE4sZAAAAJ38f3ngS6PKMFVhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ii, jj, kk = 1, 4, 1\n",
    "#\n",
    "# ii, jj, kk = np.random.randint(0, hsize, 3)\n",
    "print(ii, jj, kk, index[ii, jj, kk])\n",
    "\n",
    "diff = (pred0 - preds[ii, jj, kk]).astype(bool)\n",
    "expect = np.arange(index[ii, jj, kk]+1, index.size, 1)\n",
    "changed = index[diff]\n",
    "print(expect.size, changed.size)\n",
    "print(expect.min(), changed.min())\n",
    "\n",
    "plt.figure(figsize = (15, 4))\n",
    "for i in range(hsize):\n",
    "    plt.subplot(1, hsize, i+1)\n",
    "    plt.imshow(diff[i], vmin=0, vmax=1)\n",
    "    for ax in plt.gcf().axes: ax.set_xticks(np.arange(hsize))\n",
    "    plt.grid()\n",
    "    if i == ii:\n",
    "        plt.axhline(jj, color='r')\n",
    "        plt.axvline(kk, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ii in range(hsize):\n",
    "    for jj in range(hsize):\n",
    "        for kk in range(hsize):    \n",
    "            diff = (pred0 - preds[ii, jj, kk]).astype(bool)\n",
    "            expect = np.arange(index[ii, jj, kk]+1, index.size, 1)\n",
    "            changed = index[diff]\n",
    "            if len(set(expect) - set(changed)) > 0: print(ii, jj, kk)\n",
    "            if len(set(changed) - set(expect)) > 0: print(ii, jj, kk)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feefdc0e208>]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(expect, expect, 'o')\n",
    "plt.plot(changed, changed, 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the mesh have been generated for seed = 100\n",
      "For size =  8\n",
      "Length of targets =  1\n",
      "Supplemented by rotation :  0\n",
      "For size =  16\n",
      "Length of targets =  1\n",
      "Supplemented by rotation :  0\n",
      "For size =  32\n",
      "Length of targets =  1\n",
      "Supplemented by rotation :  0\n",
      "For size =  64\n",
      "Length of targets =  1\n",
      "Supplemented by rotation :  0\n",
      "For size =  128\n",
      "All the mesh have been generated for seed = 200\n",
      "For size =  8\n",
      "Length of targets =  1\n",
      "Supplemented by rotation :  0\n",
      "For size =  16\n",
      "Length of targets =  1\n",
      "Supplemented by rotation :  0\n",
      "For size =  32\n",
      "Length of targets =  1\n",
      "Supplemented by rotation :  0\n",
      "For size =  64\n",
      "Length of targets =  1\n",
      "Supplemented by rotation :  0\n",
      "For size =  128\n",
      "All the mesh have been generated for seed = 300\n",
      "For size =  8\n",
      "Length of targets =  1\n",
      "Supplemented by rotation :  0\n",
      "For size =  16\n",
      "Length of targets =  1\n",
      "Supplemented by rotation :  0\n",
      "For size =  32\n",
      "Length of targets =  1\n",
      "Supplemented by rotation :  0\n",
      "For size =  64\n",
      "Length of targets =  1\n",
      "Supplemented by rotation :  0\n",
      "For size =  128\n",
      "All the mesh have been generated for seed = 400\n",
      "For size =  8\n",
      "Length of targets =  1\n",
      "Supplemented by rotation :  0\n",
      "For size =  16\n",
      "Length of targets =  1\n",
      "Supplemented by rotation :  0\n",
      "For size =  32\n",
      "Length of targets =  1\n",
      "Supplemented by rotation :  0\n",
      "For size =  64\n",
      "Length of targets =  1\n",
      "Supplemented by rotation :  0\n",
      "For size =  128\n",
      "(1000, 8, 8, 8, 1) (1000, 8, 8, 8, 1)\n",
      "(500, 16, 16, 16, 1) (500, 16, 16, 16, 1)\n",
      "(248, 32, 32, 32, 1) (248, 32, 32, 32, 1)\n",
      "(124, 64, 64, 64, 1) (124, 64, 64, 64, 1)\n",
      "(4, 128, 128, 128, 1) (4, 128, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "seed_in = 3\n",
    "from numpy.random import seed\n",
    "seed(seed_in)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(seed_in)\n",
    "\n",
    "bs = 400\n",
    "nc, ncf = 128, 512\n",
    "ncp = 128\n",
    "step, stepf = 5, 40\n",
    "# path = '/data2/cosmo4d/'\n",
    "path = '../data/z00/'\n",
    "ftype = 'L%04d_N%04d_S%04d_%02dstep/'\n",
    "numd = 1e-3\n",
    "num = int(numd*bs**3)\n",
    "R1 = 3\n",
    "R2 = 3*1.2\n",
    "kny = np.pi*ncp/bs\n",
    "kk = tools.fftk((ncp, ncp, ncp), bs)\n",
    "seeds = [100, 200, 300, 400]\n",
    "\n",
    "cube_sizes = np.array([8, 16, 32, 64, 128])\n",
    "# cube_sizes = np.array([32])\n",
    "num_cubes= 500#(500*8/cube_sizes).astype('int')\n",
    "pad = 0\n",
    "cube_sizesft = cube_sizes + 2*pad\n",
    "max_offset = ncp - cube_sizes\n",
    "ftname = ['cic']\n",
    "nchannels = len(ftname)\n",
    "rprob = 0.5\n",
    "\n",
    "    \n",
    "    \n",
    "#############################\n",
    "##Read data and generate meshes\n",
    "meshes = {}\n",
    "cube_features, cube_target = [[] for i in range(len(cube_sizes))], [[] for i in range(len(cube_sizes))]\n",
    "\n",
    "for seed in seeds:\n",
    "    mesh = {}\n",
    "    partp = tools.readbigfile(path + ftype%(bs, nc, seed, step) + 'dynamic/1/Position/')\n",
    "    mesh['cic'] = tools.paintcic(partp, bs, ncp)\n",
    "\n",
    "    hmesh = {}\n",
    "    ##Uncomment for galaxies\n",
    "#     hpath = path + ftype%(bs, ncf, seed, stepf) + 'galaxies_n05/galcat/'\n",
    "#     hposd = tools.readbigfile(hpath + 'Position/')\n",
    "#     massd = tools.readbigfile(hpath + 'Mass/').reshape(-1)*1e10\n",
    "#     galtype = tools.readbigfile(hpath + 'gal_type/').reshape(-1).astype(bool)\n",
    "#     hmesh['pnnsat'] = tools.paintnn(hposd[galtype], bs, ncp)\n",
    "#     hmesh['pnncen'] = tools.paintnn(hposd[~galtype], bs, ncp)\n",
    "#     hmesh['pnn'] = tools.paintnn(hposd, bs, ncp)\n",
    "#     targetmesh = [hmesh['pnncen'], hmesh['pnnsat']]\n",
    "    \n",
    "    hposall = tools.readbigfile(path + ftype%(bs, ncf, seed, stepf) + 'FOF/PeakPosition/')[1:]    \n",
    "    hposd = hposall[:num].copy()\n",
    "#     massd = massall[:num].copy()\n",
    "    hmesh['pnn'] = tools.paintnn(hposd, bs, ncp)\n",
    "    targetmesh = [hmesh['pnn']]\n",
    "#     #hmesh['pcic'] = tools.paintcic(hposd, bs, nc)\n",
    "#     #hmesh['mnn'] = tools.paintnn(hposd, bs, ncp, massd)\n",
    "\n",
    "    meshes[seed] = [mesh, hmesh]\n",
    "\n",
    "    print('All the mesh have been generated for seed = %d'%seed)\n",
    "\n",
    "    #Create training voxels\n",
    "    ftlist = [mesh[i].copy() for i in ftname]\n",
    "    ftlistpad = [np.pad(i, pad, 'wrap') for i in ftlist]\n",
    "    ntarget = len(targetmesh)\n",
    "\n",
    "    for i, size in enumerate(cube_sizes):\n",
    "        print('For size = ', size)\n",
    "        if size==nc:\n",
    "            features = [np.stack(ftlistpad, axis=-1)]\n",
    "            target = [np.stack(targetmesh, axis=-1)]\n",
    "        else:\n",
    "            numcubes = int(num_cubes/size*4)\n",
    "            features, target = dtools.randomvoxels(ftlistpad, targetmesh, numcubes, max_offset[i],\n",
    "                                            size, cube_sizesft[i], seed=seed, rprob=0)\n",
    "        cube_features[i] = cube_features[i] + features\n",
    "        cube_target[i] = cube_target[i] + target\n",
    "\n",
    "# #\n",
    "for i in range(cube_sizes.size):\n",
    "    cube_target[i] = np.stack(cube_target[i],axis=0)\n",
    "    cube_features[i] = np.stack(cube_features[i],axis=0)\n",
    "    print(cube_features[i].shape, cube_target[i].shape)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(len(cube_sizes), 1, replace=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "rprob = 0.5\n",
    "\n",
    "def mapping_function(inds):\n",
    "    def extract_batch(inds):\n",
    "        #isize = np.random.choice(len(cube_sizes), 1, replace=True)[0]\n",
    "        isize = 2\n",
    "        batch = int(batch_size*8/cube_sizes[isize])\n",
    "        if cube_sizes[isize]==nc : batch = 1\n",
    "        inds = inds[:batch]\n",
    "        trainingsize = cube_features[isize].shape[0]\n",
    "        inds[inds >= trainingsize] =  (inds[inds >= trainingsize])%trainingsize\n",
    "\n",
    "        features = cube_features[isize][inds].astype('float32')\n",
    "        targets = cube_target[isize][inds].astype('float32')\n",
    "\n",
    "        for i in range(batch):\n",
    "            nrotations=0\n",
    "            while (np.random.random() < rprob) & (nrotations < 3):\n",
    "                nrot, ax0, ax1 = np.random.randint(0, 3), *np.random.permutation((0, 1, 2))[:2]\n",
    "                features[i] = np.rot90(features[i], nrot, (ax0, ax1))\n",
    "                targets[i] = np.rot90(targets[i], nrot, (ax0, ax1))\n",
    "                nrotations +=1\n",
    "    #         masks = np.clip(targets, 0, 1)\n",
    "    #         targets = np.concatenate((targets, masks), axis=-1)\n",
    "    #         print(targets.shape)\n",
    "#         return features, targets\n",
    "        return targets, features\n",
    "\n",
    "    ft, tg = tf.py_func(extract_batch, [inds],\n",
    "                        [tf.float32, tf.float32])\n",
    "    return ft, tg\n",
    "\n",
    "\n",
    "def training_input_fn():\n",
    "    \"\"\"Serving input fn for training data\"\"\"\n",
    "\n",
    "    dataset = tf.data.Dataset.range(len(np.array(cube_features)[0]))\n",
    "    dataset = dataset.repeat().shuffle(1000).batch(batch_size)\n",
    "    dataset = dataset.map(mapping_function)\n",
    "    dataset = dataset.prefetch(16)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def testing_input_fn():\n",
    "    \"\"\"Serving input fn for testing data\"\"\"\n",
    "    dataset = tf.data.Dataset.range(len(cube_features))\n",
    "    dataset = dataset.batch(16)\n",
    "    dataset = dataset.map(mapping_function)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model                                                                                                                       \n",
    "def PixelCNN3Dlayer(i, X, f_map=8, full_horizontal=True, h=None, filter_size=None, \n",
    "                    conditional=None, conditional_im=None, cfilter_size=None):\n",
    "\n",
    "    if len(X) == 1:\n",
    "        X_norm = X[0]\n",
    "        d_stack_in, v_stack_in, h_stack_in = X_norm, X_norm, X_norm\n",
    "    else:\n",
    "        d_stack_in, v_stack_in, h_stack_in = X\n",
    "\n",
    "    if filter_size is None:\n",
    "        filter_size = 3 if i > 0 else 5\n",
    "    if cfilter_size is None:\n",
    "        cfilter_size = filter_size\n",
    "    mask = 'b' if i > 0 else 'a'\n",
    "    residual = True if i > 0 else False\n",
    "    i = str(i)\n",
    "    with tf.variable_scope(\"d_stack\"+i):\n",
    "        d_stack = GatedCNN([filter_size, filter_size, filter_size, f_map], \n",
    "                           d_stack_in, 0, mask=mask, conditional=conditional, \n",
    "                           conditional_image=conditional_im, cfilter_size=cfilter_size).output()\n",
    "        \n",
    "        d_stack_in = d_stack\n",
    "\n",
    "    with tf.variable_scope(\"d_stack_1\"+i):\n",
    "        d_stack_1 = GatedCNN([1, 1, 1, f_map], \n",
    "                             d_stack_in, 0, gated=False, mask=None).output()\n",
    "\n",
    "    with tf.variable_scope(\"v_stack\"+i):\n",
    "        v_stack = GatedCNN([filter_size, filter_size, filter_size, f_map], \n",
    "                           v_stack_in, 1, payload = d_stack_1, mask=mask, conditional=conditional, \n",
    "                           conditional_image=conditional_im, cfilter_size=cfilter_size).output()\n",
    "        v_stack_in = v_stack\n",
    "\n",
    "    with tf.variable_scope(\"v_stack_1\"+i):\n",
    "        v_stack_1 = GatedCNN([1, 1, 1, f_map], \n",
    "                             v_stack_in, 1, gated=False, mask=None).output()\n",
    "\n",
    "    with tf.variable_scope(\"h_stack\"+i):\n",
    "        f0size = filter_size if full_horizontal else 1\n",
    "        h_stack = GatedCNN([f0size, filter_size, filter_size, f_map], \n",
    "                           h_stack_in, 2, payload=v_stack_1, mask=mask, conditional=conditional, \n",
    "                           conditional_image=conditional_im, cfilter_size=cfilter_size).output()\n",
    "\n",
    "    with tf.variable_scope(\"h_stack_1\"+i):\n",
    "        h_stack_1 = GatedCNN([1, 1, 1, f_map],\n",
    "                             h_stack, 2, gated=False, mask=None).output()\n",
    "        if residual:\n",
    "            h_stack_1 += h_stack_in # Residual connection\n",
    "        h_stack_in = h_stack_1\n",
    "\n",
    "\n",
    "    return d_stack_in, v_stack_in, h_stack_in\n",
    "\n",
    "\n",
    "def _mdn_pixmodel_fn(features, labels, nchannels, n_y, n_mixture, dropout, optimizer, mode, pad, \n",
    "                    cfilter_size=None):\n",
    "\n",
    "    # Check for training mode                                                                                                   \n",
    "    is_training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "\n",
    "    def _module_fn():\n",
    "        \"\"\"                                                                                                                     \n",
    "        Function building the module                                                                                            \n",
    "        \"\"\"\n",
    "\n",
    "        feature_layer = tf.placeholder(tf.float32, shape=[None, None, None, None, nchannels], name='input')\n",
    "        obs_layer = tf.placeholder(tf.float32, shape=[None, None, None, None, n_y], name='observations')\n",
    "\n",
    "        conditional_im = wide_resnet(feature_layer, 16, activation_fn=tf.nn.leaky_relu, \n",
    "                                     keep_prob=dropout, is_training=is_training)\n",
    "#         conditional_im = wide_resnet(conditional_im, 1, activation_fn=tf.nn.leaky_relu, \n",
    "#                                      keep_prob=dropout, is_training=is_training)\n",
    "        inputnet = obs_layer\n",
    "        \n",
    "#         fnet = wide_resnet(feature_layer, 16, activation_fn=tf.nn.leaky_relu, \n",
    "#                                      keep_prob=dropout, is_training=is_training)\n",
    "#         fnet = wide_resnet(fnet, 1, activation_fn=tf.nn.leaky_relu, \n",
    "#                                      keep_prob=dropout, is_training=is_training)\n",
    "        \n",
    "#         inputnet = tf.concat((obs_layer, fnet), axis=-1)\n",
    "#         conditional_im = None\n",
    "        # Builds the neural network                                                                                             \n",
    "        stacks0 = PixelCNN3Dlayer(0, [inputnet], f_map=8, full_horizontal=True, h=None, \n",
    "                                 conditional_im=conditional_im, cfilter_size=cfilter_size)\n",
    "        stacks1 = PixelCNN3Dlayer(1, stacks0, f_map=8, full_horizontal=True, h=None, \n",
    "                                 conditional_im=conditional_im, cfilter_size=cfilter_size)\n",
    "        stacks2 = PixelCNN3Dlayer(2, stacks1, f_map=8, full_horizontal=True, h=None, \n",
    "                                 conditional_im=conditional_im, cfilter_size=cfilter_size)\n",
    "        stacks3 = PixelCNN3Dlayer(3, stacks2, f_map=8, full_horizontal=True, h=cfilter_size, \n",
    "                                 conditional_im=conditional_im, cfilter_size=cfilter_size)\n",
    "        stacks4 = PixelCNN3Dlayer(4, stacks3, f_map=8, full_horizontal=True, h=None, \n",
    "                                 conditional_im=conditional_im, cfilter_size=cfilter_size)\n",
    "        \n",
    "        h_stack_in = stacks4[-1]\n",
    "#         print(h_stack_in)\n",
    "        \n",
    "        with tf.variable_scope(\"fc_1\"):\n",
    "            fc1 = GatedCNN([1, 1, 1, 1], h_stack_in, orientation=None, gated=False, mask='b').output()\n",
    "\n",
    "        with tf.variable_scope(\"fc_2\"):\n",
    "            fc2 = GatedCNN([1, 1, 1, n_mixture*3*n_y], fc1, orientation=None, \n",
    "                                gated=False, mask='b', activation=False).output()\n",
    "\n",
    "        \n",
    "        cube_size = tf.shape(obs_layer)[1]\n",
    "        net = tf.reshape(fc2, [-1, cube_size, cube_size, cube_size, n_y, n_mixture*3])\n",
    "\n",
    "        loc, unconstrained_scale, logits = tf.split(net,\n",
    "                                                    num_or_size_splits=3,\n",
    "                                                    axis=-1)\n",
    "        scale = tf.nn.softplus(unconstrained_scale)\n",
    "\n",
    "        # Form mixture of discretized logistic distributions. Note we shift the                                                 \n",
    "        # logistic distribution by -0.5. This lets the quantization capture \"rounding\"                                          \n",
    "        # intervals, `(x-0.5, x+0.5]`, and not \"ceiling\" intervals, `(x-1, x]`.                                                 \n",
    "#         discretized_logistic_dist = tfd.QuantizedDistribution(\n",
    "#             distribution=tfd.TransformedDistribution(\n",
    "#                 distribution=tfd.Logistic(loc=loc, scale=scale),\n",
    "#                 bijector=tfb.AffineScalar(shift=-0.5)),\n",
    "#             low=0.,\n",
    "#             high=2.**3-1)\n",
    "\n",
    "        mixture_dist = tfd.MixtureSameFamily(\n",
    "            mixture_distribution=tfd.Categorical(logits=logits),\n",
    "            components_distribution=tfd.Normal(loc, scale))\n",
    "\n",
    "        # Define a function for sampling, and a function for estimating the log likelihood                                      \n",
    "        #sample = tf.squeeze(mixture_dist.sample())                                                                             \n",
    "        sample = mixture_dist.sample()\n",
    "        loglik = mixture_dist.log_prob(obs_layer)\n",
    "        hub.add_signature(inputs={'features':feature_layer, 'labels':obs_layer},\n",
    "                          outputs={'sample':sample, 'loglikelihood':loglik,\n",
    "                                   'loc':loc, 'scale':scale, 'logits':logits})\n",
    "\n",
    "    # Create model and register module if necessary                                                                     \n",
    "    spec = hub.create_module_spec(_module_fn)\n",
    "    module = hub.Module(spec, trainable=True)\n",
    "    if isinstance(features,dict):\n",
    "        predictions = module(features, as_dict=True)\n",
    "    else:\n",
    "        predictions = module({'features':features, 'labels':labels}, as_dict=True)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        hub.register_module_for_export(module, \"likelihood\")\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    loglik = predictions['loglikelihood']\n",
    "    # Compute and register loss function                                                                                \n",
    "    neg_log_likelihood = -tf.reduce_sum(loglik, axis=-1)\n",
    "    neg_log_likelihood = tf.reduce_mean(neg_log_likelihood)\n",
    "\n",
    "    tf.losses.add_loss(neg_log_likelihood)\n",
    "    total_loss = tf.losses.get_total_loss(add_regularization_losses=True)\n",
    "\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "\n",
    "    # Define optimizer                                                                                                  \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            global_step=tf.train.get_global_step()\n",
    "            boundaries = list(np.array([2e3, 5e3, 1e4, 2e4, 3e4]).astype(int))\n",
    "            values = [1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 1e-6]\n",
    "            learning_rate = tf.train.piecewise_constant(global_step, boundaries, values)\n",
    "            train_op = optimizer(learning_rate=learning_rate).minimize(loss=total_loss, global_step=global_step)\n",
    "            tf.summary.scalar('rate', learning_rate)\n",
    "        tf.summary.scalar('loss', neg_log_likelihood)\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "\n",
    "        eval_metric_ops = { \"log_p\": neg_log_likelihood}\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                      predictions=predictions,\n",
    "                                      loss=total_loss,\n",
    "                                      train_op=train_op,\n",
    "                                      eval_metric_ops=eval_metric_ops)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MDNEstimator(tf.estimator.Estimator):\n",
    "    \"\"\"An estimator for distribution estimation using Mixture Density Networks.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_y,\n",
    "                 n_mixture,\n",
    "                 optimizer=tf.train.AdamOptimizer,\n",
    "                 dropout=None,\n",
    "                 model_dir=None,\n",
    "                 config=None):\n",
    "        \"\"\"Initializes a `MDNEstimator` instance.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        def _model_fn(features, labels, mode):\n",
    "            return _mdn_pixmodel_fn(features, labels,\n",
    "                                 nchannels, n_y, n_mixture, dropout,\n",
    "                                               optimizer, mode, pad)\n",
    "\n",
    "        super(self.__class__, self).__init__(model_fn=_model_fn,\n",
    "                                             model_dir=model_dir,\n",
    "                                             config=config)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maskpos\n",
      "maskpostest\n",
      "mass\n",
      "model0\n",
      "model1\n",
      "model2\n",
      "module0\n",
      "module02\n",
      "module1\n",
      "module2\n",
      "nozero\n",
      "pix3d\n",
      "pix3dcond\n",
      "pix3dcondv2\n",
      "README\n",
      "tmp\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "ls ./models/galmodel\n",
    "# rm -r ./models/galmodel/pix3dcond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './models/galmodel/pix3dinv/model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f63f8628390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "savepath = './models/galmodel/pix3dinv'\n",
    "\n",
    "run_config = tf.estimator.RunConfig(save_checkpoints_steps = 1000)\n",
    "\n",
    "model =  MDNEstimator(n_y=ntarget, n_mixture=8, dropout=0.95,\n",
    "                      model_dir=savepath + '/model/', config = run_config)\n",
    "#                       model_dir='./tmp/galmodel/model0', config = run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./models/galmodel/pix3dinv/model/model.ckpt.\n",
      "INFO:tensorflow:loss = 5.318751, step = 0\n",
      "INFO:tensorflow:global_step/sec: 1.40255\n",
      "INFO:tensorflow:loss = 1.2288407, step = 100 (71.300 sec)\n"
     ]
    }
   ],
   "source": [
    "model.train(training_input_fn, max_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to export\n",
    "features = tf.placeholder(tf.float32, shape=[None, None, None, None, nchannels], name='input')\n",
    "labels = tf.placeholder(tf.float32, shape=[None, None, None, None, ntarget], name='observations')\n",
    "    \n",
    "exporter = hub.LatestModuleExporter(\"tf_hub\", tf.estimator.export.build_raw_serving_input_receiver_fn({'features':features, 'labels':labels},\n",
    "                                                                   default_batch_size=None))\n",
    "\n",
    "modulepath = exporter.export(model, savepath + '/module/', model.latest_checkpoint())\n",
    "modulepath = modulepath.decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "module = hub.Module(modulepath + '/likelihood/')\n",
    "# module = pad4-nozero_maskpos_rewt/module/1554184418\n",
    "# module = hub.Module('../code/models/n10/pad4-nozero_maskpos_rewt/module/1554184418/likelihood/')\n",
    "xx = tf.placeholder(tf.float32, shape=[None, None, None, None, nchannels], name='input')\n",
    "yy = tf.placeholder(tf.float32, shape=[None, None, None, None, ntarget], name='labels')\n",
    "samples = module(dict(features=xx, labels=yy), as_dict=True)['sample']\n",
    "loglik = module(dict(features=xx, labels=yy), as_dict=True)['loglikelihood']\n",
    "# loss = module(dict(features=xx, labels=yy), as_dict=True)['loss']\n",
    "# loss1 = module(dict(features=xx, labels=yy), as_dict=True)['loss1']\n",
    "# loss2 = module(dict(features=xx, labels=yy), as_dict=True)['loss2']\n",
    "# out_masks =  module(dict(features=xx, labels=yy), as_dict=True)['out_mask']\n",
    "# pred_masks =  module(dict(features=xx, labels=yy), as_dict=True)['pred_mask']\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initializers.global_variables())\n",
    "        \n",
    "#     features = cube_features[2][0:8].astype('float32')\n",
    "#     targets = cube_target[2][0:8].astype('float32')\n",
    "    features = cube_target[2][0:8].astype('float32')\n",
    "    targets = cube_features[2][0:8].astype('float32')\n",
    "    xxm = features\n",
    "    yym = targets\n",
    "    \n",
    "    print(xxm.shape, yym.shape)\n",
    "    loss = sess.run(tf.squeeze(loglik), feed_dict={xx:xxm, yy:yym})\n",
    "\n",
    "#     xxn = np.fft.irfftn(np.fft.rfftn(xxm, axes=(1, 2, 3), norm='ortho')/2., axes=(1, 2, 3), norm='ortho')\n",
    "    xxn = np.roll(xxm, 16, 1)\n",
    "    xxn = xxm\n",
    "    yyn = yym\n",
    "    yyn = np.roll(yym, 7, 1)\n",
    "    loss2 = sess.run(tf.squeeze(loglik), feed_dict={xx:xxn, yy:yyn})\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(loss[1].sum(axis=0))\n",
    "plt.colorbar()\n",
    "plt.subplot(122)\n",
    "plt.imshow(loss2[1].sum(axis=0))\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initializers.global_variables())\n",
    "        \n",
    "#     features = cube_features[1][0:1].astype('float32')\n",
    "#     targets = cube_target[1][0:1].astype('float32')\n",
    "    features = cube_target[1][0:1].astype('float32')\n",
    "    targets = cube_features[1][0:1].astype('float32')\n",
    "    xxm = features\n",
    "    yym = targets\n",
    "\n",
    "    sample = np.zeros_like(yym)\n",
    "    sample2 = sess.run(samples, feed_dict={xx:xxm, yy:yym*0})\n",
    "    for i in range(yym.shape[1]):\n",
    "        for j in range(yym.shape[2]):\n",
    "            for k in range(yym.shape[3]):\n",
    "                data_dict = {xx:xxm, yy:sample}\n",
    "                next_sample = sess.run(samples, feed_dict=data_dict)\n",
    "                sample[:, i, j, k, :] = next_sample[:, i, j, k, :]\n",
    "    \n",
    "#     print(sess.run(tf.squeeze(loglik), feed_dict={xx:xxm, yy:np.expand_dims(sample, axis=-1)}))\n",
    "    loss = sess.run(tf.squeeze(loglik), feed_dict={xx:xxm, yy:sample})\n",
    "    loss2 = sess.run(tf.squeeze(loglik), feed_dict={xx:xxm, yy:sample2})\n",
    "\n",
    "end = time()\n",
    "print('Taken : ', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yym = np.squeeze(yym)\n",
    "# sample  = np.squeeze(sample) \n",
    "# sample2 = np.squeeze(sample2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(loss[0,...], vmin=0, vmax=-1)\n",
    "plt.colorbar()\n",
    "plt.subplot(122)\n",
    "plt.imshow(loss2[0,...], vmin=0, vmax=-1)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.sum(), loss2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[0].sum(), sample2[0].sum(), yym[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = 0, 7\n",
    "\n",
    "plt.figure(figsize = (12, 4))\n",
    "plt.subplot(131)\n",
    "plt.imshow(yym[0,...,0].sum(axis=0), vmin=vmin, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.subplot(132)\n",
    "plt.imshow(sample[0,...,0].sum(axis=0), vmin=vmin, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.subplot(133)\n",
    "plt.imshow(sample2[0,...,0].sum(axis=0), vmin=vmin, vmax=vmax)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 0\n",
    "k, ph = tools.power(yym[ii,...,], boxsize=bs/4)\n",
    "k, pp1 = tools.power(sample[ii,...,], boxsize=bs/4)\n",
    "k, pp1x = tools.power(sample[ii,...,], yym[ii,...,], boxsize=bs/4)\n",
    "k, pp2 = tools.power(sample2[ii,...,], boxsize=bs/4)\n",
    "k, pp2x = tools.power(sample2[ii,...,], yym[ii,...,], boxsize=bs/4)\n",
    "\n",
    "\n",
    "plt.figure(figsize = (10, 4))\n",
    "plt.subplot(121)\n",
    "# plt.plot(k, ph, 'C%d-'%ii)\n",
    "plt.plot(k, pp1/ph, 'C%d--'%ii)\n",
    "plt.plot(k, pp2/ph, 'C%d:'%ii)\n",
    "plt.ylim(0, 1.5)\n",
    "plt.grid(which='both')\n",
    "plt.semilogx()\n",
    "# plt.loglog()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(k, pp1x/(pp1*ph)**0.5, 'C%d--'%ii)\n",
    "plt.plot(k, pp2x/(pp2*ph)**0.5, 'C%d:'%ii)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(which='both')\n",
    "plt.semilogx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(*tools.power(yym[0,...,], boxsize=bs), 'C0--')\n",
    "plt.plot(*tools.power(yym[1,...,], boxsize=bs), 'C1--')\n",
    "plt.plot(*tools.power(sample[0,...], boxsize=bs), 'C0-')\n",
    "plt.plot(*tools.power(sample[1,...], boxsize=bs), 'C1-')\n",
    "plt.plot(*tools.power(sample2[0,...], boxsize=bs), 'C0:')\n",
    "plt.plot(*tools.power(sample2[1,...], boxsize=bs), 'C1:')\n",
    "plt.loglog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
